# Thesis Plan â€” EMAC+ Research

> **Your status:** Thesis A âœ… presentation done, âœ… 3 RQs defined. Today: 22 Feb 2026.
> **Working schedule:** 5 days/week including term breaks.
> **Total time:** 43 weeks (214 working days) until 18 Dec 2026.
>
> Tick tasks with `[x]` as you finish them. This is your single source of truth.

---

## Environment Decision (Final)

| RQ      | Environment  | Reason                                                                                                     |
| ------- | ------------ | ---------------------------------------------------------------------------------------------------------- |
| **RQ1** | ALFWorld     | Already set up. Fast. Get results in Term 1.                                                               |
| **RQ2** | **AI2-THOR** | Real egocentric camera = genuine partial observability. Much stronger than BabyAI-Text for stuck/recovery. |
| **RQ3** | ScienceWorld | 30-60 step tasks = memory compression matters. Has CLIN published baseline to compare against.             |

> ~~**Fallback rule for RQ2:** If AI2-THOR is not working by **21 May (Week 14)**, switch to BabyAI-Text.~~ **Resolved** â€” AI2-THOR confirmed working on Katana GPU nodes (Feb 2026). Use `platform=CloudRendering` + `xvfb-run -a`.

---

## 3 Research Questions

| RQ      | Question                                                                                | Hypotheses                                                                                                  |
| ------- | --------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------- |
| **RQ1** | How does enriching the feedback signal affect training efficiency and task success?     | H1: Shaped feedback improves success vs binary. H2: Anti-repeat reduces loops.                              |
| **RQ2** | How does stuck-detection and recovery policy affect failure-loop frequency and success? | H1: Recovery reduces loops. H2: Backtracking better than scan. H3: Stagnation trigger reduces false alarms. |
| **RQ3** | How does memory representation affect improvement across re-attempts?                   | H1: Reflections improve attempt-to-attempt vs raw. H2: Hybrid performs best.                                |

---

## WEEK-BY-WEEK SCHEDULE

### TERM 1 â€” 22 Feb to 30 Apr (10 weeks)

> **Goal:** Thesis A report submitted + EMAC+ code running + RQ1 implemented + AI2-THOR setup begun.

---

**Week 1 â€” 22 Feb to 26 Feb**

- [ ] Read the **EMAC+ paper** fully â€” take structured notes (see Guide.md Â§1 and Â§2)
- [x] Install conda, create `emac` Python 3.9 environment
- [x] Run `conda env create -f environment.yml` + `pip install -e . --no-deps` â€” full environment set up
- [x] Create Overleaf project with faculty LaTeX thesis template

---

**Week 2 â€” 1 Mar to 5 Mar**

- [ ] Read **ReAct paper** (Yao et al., 2022) â€” take notes
- [ ] Read **Reflexion paper** (Shinn et al., 2023) â€” take notes
- [x] Download Vicuna-7B-v1.1 weights to HPC (start download, it takes hours)
- [x] Install ALFWorld and download its game data
- [x] Confirm ALFWorld launches without errors

---

**Week 3 â€” 8 Mar to 12 Mar**

- [ ] Read **DPO paper** (Rafailov et al., 2023) â€” take notes
- [ ] Read **InstructBLIP paper** (Dai et al., 2023) â€” take notes
- [x] Run first EMAC+ baseline test: `num_envs=10, num_rounds=2, run_training=False`
- [x] Confirm dagger_server.py and ALFWorld client communicate (2-terminal setup)
- [ ] Record preliminary success rate in experiment_log.md

---

**Week 4 â€” 15 Mar to 19 Mar**

- [ ] Read **ALFWorld paper** (Shridhar et al., 2021)
- [ ] Read **AI2-THOR / ALFRED paper** (Kolve et al., 2017 / Shridhar et al., 2020) â€” for RQ2 background
- [ ] Read **reward shaping paper** (Ng et al., 1999) â€” for RQ1 background
- [ ] Write **Introduction section** of Thesis A report in Overleaf (~3 pages)

---

**Week 5 â€” 22 Mar to 26 Mar**

- [ ] Read **CLIN paper** (Majumder et al., 2023) â€” for RQ3 background
- [ ] Read **ScienceWorld paper** (Wang et al., 2022) â€” for RQ3 environment
- [ ] Write **Literature Review section** Part 1: Embodied AI agents, ReAct, Reflexion (~5 pages)

---

**Week 6 â€” 29 Mar to 2 Apr**

- [ ] Read **Generative Agents** (Park et al., 2023) â€” agents with memory and planning
- [ ] Write **Literature Review section** Part 2: EMAC+, DPO, VLM+LLM approaches (~5 pages)
- [ ] Write **Literature Review section** Part 3: Environments (ALFWorld, AI2-THOR, ScienceWorld) (~3 pages)
- [x] Install `ai2thor` Python package + confirm working on Katana with `platform=CloudRendering` + `xvfb-run -a`

---

**Week 7 â€” 5 Apr to 9 Apr**

- [ ] Write **Research Gaps section** in Thesis A report (~2 pages â€” 3 clear gaps matching your 3 RQs)
- [ ] Write **Research Questions section** in Thesis A report (~2 pages â€” formal statement of RQ1, RQ2, RQ3 with hypotheses)
- [x] AI2-THOR basic environment test passed â€” FloorPlan1 loads, egocentric camera shows partial obs âœ…

---

**Week 8 â€” 12 Apr to 16 Apr**

- [ ] Write **Preliminary Experiments section** in Thesis A report (describe your Week 3 baseline test + results)
- [ ] Write **Research Timeline section** in Thesis A report (use this Plan.md as reference)
- [ ] Begin **RQ1 implementation**: write `extract_progress_signal()` and `classify_failure()` functions in dagger_server.py
- [ ] Test these functions in isolation: `python test_rq1_functions.py`

---

**Week 9 â€” 19 Apr to 23 Apr**

- [ ] Write **Abstract** for Thesis A report
- [ ] Proofread and compile full Thesis A report in Overleaf
- [ ] Implement **anti-repeat penalty** using `check_is_exhausted()` in dagger_server.py
- [ ] Integrate all 3 RQ1 signals into the VLM prompt in dagger_server.py
- [ ] Run a 3-env test confirming RQ1 signals appear in logs

---

**Week 10 â€” 26 Apr to 30 Apr**

- [ ] **Submit Thesis A report** âœ…
- [ ] Fix any remaining RQ1 code bugs from Week 9 testing
- [ ] Git commit all RQ1 code changes: `git checkout -b rq1-feedback-shaping && git commit`
- [ ] Start drafting RQ2 environment adapter (understand ALFRED action space)

---

### BREAK 1 â€” 1 May to 31 May (4 weeks)

> **Goal:** Run all RQ1 experiments. Get AI2-THOR working. Decide final RQ2 environment by Week 14.

---

**Week 11 â€” 3 May to 7 May**

- [ ] Run **RQ1 Condition 0 (Baseline)**: 10 envs, 3 rounds, no modifications â€” record results
- [ ] Run **RQ1 Condition A**: progress-shaped feedback only â€” record results
- [x] AI2-THOR environment loading and rendering confirmed working âœ… (completed Week 6-7, ahead of schedule)

---

**Week 12 â€” 10 May to 14 May**

- [ ] Run **RQ1 Condition B**: failure-type feedback only â€” record results
- [ ] Run **RQ1 Condition C**: anti-repeat penalty only â€” record results
- [ ] Deep dive AI2-THOR: understand the action space, observation format, HTTP/gym API

---

**Week 13 â€” 17 May to 21 May**

- [ ] Run **RQ1 Condition D**: all three signals combined â€” record results
- [ ] Record all RQ1 results in a table in experiment_log.md
- [ ] Plot RQ1 learning curves (success rate per round, all conditions on one graph)

---

**Week 14 â€” 24 May to 28 May** âš ï¸ DECISION POINT

- [x] **AI2-THOR decision: confirmed working** â€” write adapter for dagger_server.py (AI2-THOR confirmed Feb 2026, weeks ahead of this deadline)
- [ ] Write the chosen RQ2 environment adapter (wrap gym API to match dagger_server.py HTTP format)
- [ ] Analyse RQ1 results: does shaped feedback help? Write 1-page analysis.

---

**Week 15 â€” 31 May to 4 Jun** _(week spans break + Term 2 start)_

- [ ] Test RQ2 adapter: confirm dagger_server.py receives observations from new environment
- [ ] Run 3-environment sanity check in RQ2 environment
- [ ] Write first draft of **Introduction** for main thesis report in Overleaf (reuse and expand Thesis A intro)

---

### TERM 2 â€” 1 Jun to 13 Aug (10 weeks)

> **Goal:** Complete RQ2 experiments. Set up ScienceWorld. Write Introduction + Background + System Design chapters. Thesis B presentation.

---

**Week 16 â€” 7 Jun to 11 Jun**

- [ ] Implement `detect_stuck_A()` â€” same action fails twice
- [ ] Implement `detect_stuck_B()` â€” N steps without progress (threshold=4)
- [ ] Implement `track_progress_checkpoints()` â€” record (step, obs) when progress occurs
- [ ] Unit test all three functions

---

**Week 17 â€” 14 Jun to 18 Jun**

- [ ] Implement `recovery_scan()` â€” inject `look` + context message into prompt
- [ ] Implement `recovery_backtrack()` â€” logical plan revert to last checkpoint
- [ ] Test on 3 RQ2 environments â€” confirm stuck events trigger and recovery fires

---

**Week 18 â€” 21 Jun to 25 Jun**

- [ ] Fix any bugs from Week 17 testing
- [ ] Git commit all RQ2 code: `git checkout -b rq2-stuck-recovery && git commit`
- [ ] Run **RQ2 Condition 0 (Baseline)**: no detector, no recovery â€” record results
- [ ] Run **RQ2 Condition A**: Stuck-A only, no recovery â€” record results

---

**Week 19 â€” 28 Jun to 2 Jul**

- [ ] Run **RQ2 Condition B**: Stuck-B only, no recovery â€” record results
- [ ] Run **RQ2 Condition C**: Stuck-A + Policy 1 (scan) â€” record results
- [ ] Run **RQ2 Condition D**: Stuck-A + Policy 2 (backtrack) â€” record results

---

**Week 20 â€” 5 Jul to 9 Jul**

- [ ] Run **RQ2 Condition E**: Stuck-B + Policy 1 (scan) â€” record results
- [ ] Run **RQ2 Condition F**: Stuck-B + Policy 2 (backtrack) â€” record results
- [ ] Record all RQ2 results in table + plot learning curves

---

**Week 21 â€” 12 Jul to 16 Jul**

- [ ] Analyse RQ2 results: which detector + policy combination is best? Write 1-page analysis.
- [ ] Write **Background / Literature Review** chapter for main thesis (expand from Thesis A, 15-20 pages)

---

**Week 22 â€” 19 Jul to 23 Jul**

- [ ] Write **System Design** chapter: EMAC+ architecture + your 3 modifications with diagrams (10-15 pages)
- [ ] Create architecture diagrams in draw.io (ViTâ†’QFormerâ†’LLM, DAgger loop, RQ1 modification)
- [x] Install ScienceWorld and Java â€” see Guide.md Â§4.3

---

**Week 23 â€” 26 Jul to 30 Jul**

- [ ] Explore ScienceWorld: run 3 task types (boil, freeze, react) â€” understand observation format
- [ ] Choose which ScienceWorld tasks to use for RQ3 â€” write 1-paragraph justification
- [ ] Write adapter to connect ScienceWorld to dagger_server.py loop

---

**Week 24 â€” 2 Aug to 6 Aug**

- [ ] Test ScienceWorld adapter on 3 environments â€” confirm end-to-end communication works
- [ ] Prepare **Thesis B presentation** slides (10-15 slides): RQ1 results, RQ2 status, RQ3 plan
- [ ] Write **Methodology** chapter section on RQ1 + RQ2 experimental design

---

**Week 25 â€” 9 Aug to 13 Aug**

- [ ] **Deliver Thesis B presentation** âœ…
- [ ] Buffer week: catch up on anything delayed, polish presentation

---

### BREAK 2 â€” 14 Aug to 13 Sep (4 weeks)

> **Goal:** Complete all RQ3 experiments. Write RQ3 results. Keep writing thesis report.

---

**Week 26 â€” 16 Aug to 20 Aug**

- [ ] Implement `get_raw_trajectory_memory(env_history, last_k=5)` in dagger_server.py
- [ ] Implement `get_hybrid_memory(env_history, reflections, last_k=5)` in dagger_server.py
- [ ] Add `memory_type` flag that switches between: `none`, `raw`, `reflection`, `hybrid`

---

**Week 27 â€” 23 Aug to 27 Aug**

- [ ] Test all 3 memory types on 2 ScienceWorld environments â€” confirm memory appears correctly in prompts
- [ ] Git commit: `git checkout -b rq3-memory && git commit`
- [ ] Run **RQ3 Condition 0 (No memory)**: record success at attempt 1, 2, 3

---

**Week 28 â€” 30 Aug to 3 Sep**

- [ ] Run **RQ3 Condition A**: raw recent trajectory â€” record success per attempt
- [ ] Run **RQ3 Condition B**: Reflexion only (existing EMAC+ approach) â€” record success per attempt
- [ ] Run **RQ3 Condition C**: hybrid (raw + reflection) â€” record success per attempt

---

**Week 29 â€” 6 Sep to 10 Sep**

- [ ] Record all RQ3 results in table (rows = conditions, columns = attempt 1/2/3)
- [ ] Plot RQ3 results: bar chart of success per attempt per condition
- [ ] Analyse results: which memory type shows strongest improvement across attempts?

---

**Week 30 â€” 13 Sep to 17 Sep** _(spans Break 2 and Term 3 start)_

- [ ] Write **RQ1 Results** section for main thesis (tables + figures + analysis)
- [ ] Write **RQ2 Results** section for main thesis (tables + figures + analysis)

---

### TERM 3 â€” 14 Sep to 18 Dec (14 weeks)

> **Goal:** Finalise all results. Write complete thesis report. Final presentation. Submit.

---

**Week 31 â€” 20 Sep to 24 Sep**

- [ ] Write **RQ3 Results** section for main thesis (tables + figures + analysis)
- [ ] Re-run any experiments that had issues or need more data

---

**Week 32 â€” 27 Sep to 1 Oct**

- [ ] Write **Discussion** chapter: synthesise all 3 RQs â€” do results confirm hypotheses? (~5-8 pages)
- [ ] Create all remaining diagrams: DAgger loop, stuck-detection flowchart, memory diagram

---

**Week 33 â€” 4 Oct to 8 Oct**

- [ ] Write **Conclusion** chapter: answer each RQ in 2-3 sentences, state limitations, suggest future work (~3 pages)
- [ ] Write **Experimental Setup** chapter: environments, hyperparameters, hardware, metrics (~5 pages)

---

**Week 34 â€” 11 Oct to 15 Oct**

- [ ] Write **Abstract** for main thesis (~half page)
- [ ] Finalise **Introduction** chapter â€” write last after everything else is done
- [ ] First complete draft of all chapters assembled

---

**Week 35 â€” 18 Oct to 22 Oct**

- [ ] Read through full draft from start to end â€” mark all gaps and inconsistencies
- [ ] Fix all sections flagged in the read-through
- [ ] Send draft to supervisor for feedback

---

**Week 36 â€” 25 Oct to 29 Oct**

- [ ] Address supervisor feedback
- [ ] Polish all figures and tables (consistent style, captions complete, all referenced in text)
- [ ] Check all citations in references.bib are complete and formatted correctly

---

**Week 37 â€” 1 Nov to 5 Nov**

- [ ] Second full read-through â€” fix grammar, clarity, flow
- [ ] Ensure every figure and table is referenced from the text
- [ ] Compile PDF and check formatting (margins, font size, page numbers)

---

**Week 38 â€” 8 Nov to 12 Nov**

- [ ] Final proofread â€” word by word if possible
- [ ] Ask a friend/colleague to read one chapter for clarity
- [ ] Final PDF ready

---

**Week 39 â€” 15 Nov to 19 Nov**

- [ ] **Create final presentation** slides (20-25 slides): all 3 RQs + results + conclusion
- [ ] Create all presentation diagrams and result visualisations

---

**Week 40 â€” 22 Nov to 26 Nov**

- [ ] Practice presentation out loud 3 times
- [ ] Time yourself: aim for 20 min talk + 5 min Q&A prep
- [ ] Prepare answers for likely questions (What if results are negative? How does this compare to paper X?)

---

**Week 41 â€” 29 Nov to 3 Dec**

- [ ] **Deliver final presentation** âœ…
- [ ] Final polish of thesis report based on presentation Q&A feedback

---

**Week 42 â€” 6 Dec to 10 Dec**

- [ ] **Submit final thesis report** âœ…
- [ ] Buffer week

---

**Week 43 â€” 13 Dec to 17 Dec**

- [ ] Hard deadline: 18 Dec 2026
- [ ] Done. ğŸ“

---

## Visual Timeline (One-Page Overview)

```
TERM 1  â”‚Feb22â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€Apr30â”‚
Wk 1-3  â”‚ Read papers + Set up code + Run baseline      â”‚
Wk 4-7  â”‚ Write Thesis A report                         â”‚
Wk 8-10 â”‚ Implement RQ1 + Submit report                 â”‚

BREAK 1 â”‚May1â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€May31â”‚
Wk 11-13â”‚ Run ALL RQ1 experiments + Analyse             â”‚
Wk 14-15â”‚ âš ï¸ AI2-THOR decision + RQ2 adapter built      â”‚

TERM 2  â”‚Jun1â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€Aug13â”‚
Wk 16-17â”‚ Implement RQ2 (stuck detectors + recovery)    â”‚
Wk 18-20â”‚ Run ALL RQ2 experiments                       â”‚
Wk 21-22â”‚ Analyse RQ2 + Write Background chapter        â”‚
Wk 23-24â”‚ ScienceWorld setup + Write System Design      â”‚
Wk 25   â”‚ Thesis B Presentation ğŸ¤                      â”‚

BREAK 2 â”‚Aug14â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€Sep13â”‚
Wk 26-27â”‚ Implement RQ3 memory types                    â”‚
Wk 28-29â”‚ Run ALL RQ3 experiments                       â”‚
Wk 30   â”‚ Write RQ1 + RQ2 results chapters              â”‚

TERM 3  â”‚Sep14â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€Dec18â”‚
Wk 31   â”‚ Write RQ3 results chapter                     â”‚
Wk 32-33â”‚ Write Discussion + Conclusion + Exp Setup     â”‚
Wk 34   â”‚ First complete draft assembled                â”‚
Wk 35-36â”‚ Supervisor feedback â†’ revise                  â”‚
Wk 37-38â”‚ Final proofread + polish                      â”‚
Wk 39-40â”‚ Final presentation prep + practice            â”‚
Wk 41   â”‚ Final Presentation ğŸ¤ + Submit ğŸ“             â”‚
Wk 42-43â”‚ Buffer                                        â”‚
```

---

## Progress Tracker

Update status as you go: â¬œ Not started â†’ ğŸ”„ In progress â†’ âœ… Done

| Week  | Task                           | Status  | Notes                                           |
| ----- | ------------------------------ | ------- | ----------------------------------------------- |
| -     | Thesis A presentation          | âœ… Done |                                                 |
| -     | 3 RQs defined                  | âœ… Done |                                                 |
| 1     | Read EMAC+ paper               | â¬œ      |                                                 |
| 1     | Set up conda + install deps    | âœ… Done | environment.yml + pip install -e . --no-deps    |
| 2     | Read ReAct + Reflexion         | â¬œ      |                                                 |
| 2     | ALFWorld working               | âœ… Done |                                                 |
| 2     | Vicuna-7B downloaded           | âœ… Done | On /srv/scratch                                 |
| 6     | AI2-THOR installed + working   | âœ… Done | CloudRendering + xvfb-run -a on Katana GPU      |
| 3     | Run baseline EMAC+ (10 envs)   | â¬œ      |                                                 |
| 4-9   | Write Thesis A report          | â¬œ      |                                                 |
| 8-9   | RQ1 code implemented           | â¬œ      |                                                 |
| 10    | Submit Thesis A report         | â¬œ      |                                                 |
| 11-13 | All 5 RQ1 experiments run      | â¬œ      |                                                 |
| 14    | AI2-THOR decision made         | âœ… Done | AI2-THOR confirmed working Feb 2026             |
| 16-17 | RQ2 stuck+recovery implemented | â¬œ      |                                                 |
| 18-20 | All 7 RQ2 experiments run      | â¬œ      |                                                 |
| 23    | ScienceWorld working           | â¬œ      | Installed via environment.yml â€” run verify test |
| 25    | Thesis B presentation          | â¬œ      |                                                 |
| 26-27 | RQ3 memory types implemented   | â¬œ      |                                                 |
| 28-29 | All 4 RQ3 experiments run      | â¬œ      |                                                 |
| 34    | First full thesis draft        | â¬œ      |                                                 |
| 41    | Final presentation + submit    | â¬œ      |                                                 |

---

## Paper Reading List

Mark as you go: [R] Read [N] Notes taken [W] Written about in report

### Week 1-3 (Essential â€” read first)

- [ ] [R][N][W] EMAC+ paper _(the paper this code is based on)_
- [ ] [R][N][W] ReAct â€” Yao et al., 2022
- [ ] [R][N][W] Reflexion â€” Shinn et al., 2023
- [ ] [R][N][W] InstructBLIP â€” Dai et al., 2023
- [ ] [R][N][W] DPO â€” Rafailov et al., 2023
- [ ] [R][N][W] ALFWorld â€” Shridhar et al., 2021

### Week 4-6 (RQ background)

- [ ] [R][N] Reward Shaping â€” Ng et al., 1999 _(RQ1)_
- [ ] [R][N] SayCan â€” Ahn et al., 2022 _(RQ1)_
- [ ] [R][N][W] AI2-THOR â€” Kolve et al., 2017 _(RQ2 environment paper)_
- [ ] [R][N][W] ALFRED â€” Shridhar et al., 2020 _(RQ2 task benchmark on AI2-THOR)_
- [ ] [R][N][W] CLIN â€” Majumder et al., 2023 _(RQ3)_
- [ ] [R][N][W] ScienceWorld â€” Wang et al., 2022 _(RQ3 environment)_
- [ ] [R][N] Generative Agents â€” Park et al., 2023 _(RQ3 background)_

### Bonus (read if time allows in Term 2)

- [ ] [R][N] MemoryBank â€” Zhong et al., 2023
- [ ] [R][N] VOYAGER â€” Wang et al., 2023 _(agent with skill library)_
- [ ] [R][N] AgentBench â€” Liu et al., 2023 _(benchmarking agents)_

---

## Experiment Log Template

Copy this block each time you run an experiment. Keep in `experiment_log.md`.

```
## Experiment: [RQ1/RQ2/RQ3] Condition [X]
Date:
Config: num_envs=, num_rounds=, seed=, feedback=, stuck=, memory=
Command:
GPU:
Runtime:

| Round | Success | Accuracy | Avg Steps | Notes |
|-------|---------|----------|-----------|-------|
| 0     |         |          |           |       |
| 1     |         |          |           |       |
| 2     |         |          |           |       |

Observations:
Issues:
Next step:
```
